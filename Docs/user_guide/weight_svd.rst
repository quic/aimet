################
AIMET weight SVD
################

Weight singular value decomposition (SVD) is a technique that decomposes one large layer (in terms of MAC or memory) into two smaller layers.

Consider a neural network layer with the kernel (ğ‘š,ğ‘›,â„,ğ‘¤) where:

- ğ‘š is the input channels
-  ğ‘› the output channels
-  â„ is the height of the kernel
-  ğ‘¤ is the width of the kernel 

Weight SVD decomposes the kernel into one of size (ğ‘š,ğ‘˜,1,1) and another of size (ğ‘˜,ğ‘›,h,ğ‘¤), where ğ‘˜ is called the `rank`. The smaller the value of ğ‘˜, larger the degree of compression.

The following figure illustrates how weight SVD decomposes the output channel dimension. Weight SVD is currently supported for convolution (`Conv`) and fully connected (FC) layers in AIMET.

.. image:: ../images/weight_svd.png
    :width: 900px
